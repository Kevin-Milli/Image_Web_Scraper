{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb8b8b8-de08-4dfd-bf6b-1d35c0b539f4",
   "metadata": {},
   "source": [
    "# Image Scraper\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Kevin Milli\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "The aim of this notebook is to develop a script for extracting high-resolution images from the website [Unsplash](https://unsplash.com/).\n",
    "\n",
    "## Process Description\n",
    "\n",
    "This section, dedicated to data extraction via web scraping, will primarily be used to retrieve images resulting from a specific search.<br>\n",
    "Subsequently, premium images and user profile images will be removed. Finally, the resulting images will be downloaded in high-resolution format.\n",
    "\n",
    "## Approach to the Problem\n",
    "\n",
    "The approach adopted involves the utilization of the following Python libraries:\n",
    "- `requests`\n",
    "- `BeautifulSoup`\n",
    "- `os`\n",
    "\n",
    "Four main functions have been implemented:\n",
    "1. `get_img_tags_for`: Used to select all images from the website using BeautifulSoup.\n",
    "2. `img_filter_out`: Employed to filter URLs based on specific keywords.\n",
    "3. `get_high_res_img_url`: Applies data filtering using the `img_filter_out` function.\n",
    "4. `save_images`: Downloads images in JPG format, taking a list of images as input.\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "Gratitude is expressed to the entire staff of [Unsplash](https://unsplash.com/) for their availability and the quality of the content provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5143af7e-6e60-4525-8b1e-11502cf0c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511e6cc5-7c79-40b3-ac65-7a6dd9423cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e5ab87-2d40-49ea-920b-2bbd41effab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tags_for(term=None):\n",
    "    \"\"\"\n",
    "    Fetches data from the server, performing image scraping.\n",
    "\n",
    "    Parameters:\n",
    "    term : str, optional\n",
    "        The search term to fetch images for.\n",
    "\n",
    "    Returns:\n",
    "    BeautifulSoup object\n",
    "        A list of image tags obtained from BeautifulSoup.\n",
    "        \n",
    "    Raises:\n",
    "    Exception\n",
    "        If no search term is provided or if there is an error getting the response from the server.\n",
    "    \"\"\"\n",
    "    if term == None:\n",
    "        raise Exception(\"You Must insert something to search\")\n",
    "    \n",
    "    url = f\"https://unsplash.com/s/foto/{term}\"\n",
    "    resp = r.get(url)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(\"Error Getting response\")\n",
    "\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    img_tags = soup.select(\"figure a img\")\n",
    "\n",
    "    return img_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd4f13d-d243-4957-a404-722d4c15c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter_out(url, keywords):\n",
    "    \"\"\"\n",
    "    Remove URLs containing any of the specified keywords.\n",
    "    \n",
    "    Parameters:\n",
    "    url : str\n",
    "        URL of the image.\n",
    "    keywords : list of str\n",
    "        List of keywords to be removed from URLs.\n",
    "        \n",
    "    Returns:\n",
    "    bool\n",
    "        True if the URL does not contain any of the keywords, False otherwise.\n",
    "    \"\"\"\n",
    "    return not any(x in url for x in keywords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ee014ac-2e93-4b53-8e54-dc47a13aee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_res_img_url(img_tags, keywords=[\"premium\",\"plus\",\"profile\"]):\n",
    "    \"\"\"\n",
    "    This function applies data filtering using the img_filter_out function.\n",
    "    \n",
    "    Parameters:\n",
    "    img_tags : BeautifulSoup \"list of images\"\n",
    "        A list of image tags obtained from BeautifulSoup.\n",
    "    keywords : list of strings, optional\n",
    "        A list of keywords to filter out unwanted images. Default is [\"premium\",\"plus\",\"profile\"].\n",
    "        \n",
    "    Returns:\n",
    "    list\n",
    "        A list of URLs of filtered images based on specified conditions.\n",
    "    \"\"\"\n",
    "    img_urls = [img['srcset'].split() for img in img_tags if img['src'].startswith(\"h\")]\n",
    "    hd_content = [img[-2:-1][0] for img in img_urls]\n",
    "    final_hd_urls = [i for i in hd_content if img_filter_out(i, keywords)]\n",
    "\n",
    "    return final_hd_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c94e22dc-5efb-46ff-8571-0923cc479da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(img_urls, dest_dir=\"image\", tag=\"\"):\n",
    "    \"\"\"\n",
    "    Save images to a destination folder.\n",
    "    \n",
    "    Parameters:\n",
    "    img_urls : list\n",
    "        List of URLs of images to be saved.\n",
    "    dest_dir : str, optional\n",
    "        Destination directory where images will be saved. Default is \"image\".\n",
    "    tag : str, optional\n",
    "        Tag to be added to the beginning of each saved image file name. Default is an empty string.\n",
    "    \"\"\"\n",
    "    for url in img_urls:\n",
    "        resp = r.get(url)\n",
    "        logging,info(f\"Downloading {url} ...\")\n",
    "        file_name = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.mkdir(dest_dir)\n",
    "\n",
    "        with open(f\"{dest_dir}/{tag}{file_name}.jpeg\", \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "            logging,info(f\"Saved {file_name}, with size {round((resp.content)/1024/1024, 2)} MB.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a817bf7c-c49e-492b-ab34-269260d8ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending the request and getting all images\n",
    "imgs = get_img_tags_for(\"Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "300896c3-51c0-427c-81b5-b8bf81a8453d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering data to obtain images in HD resolution\n",
    "ia_imgs = get_high_res_img_url(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90f89c38-6612-4203-877b-90b01eda2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images to a given folder -> images\n",
    "save_images(ia_imgs, \"images\", \"Artifiicial_Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac49a43-5d6e-44ad-a418-b1248dfedcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
